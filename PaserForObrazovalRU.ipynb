{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import HTTPError\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Списки с данными.\n",
    "title = []\n",
    "company = []\n",
    "price = []\n",
    "raiting_company = []\n",
    "raiting_course = []\n",
    "descr_course = []\n",
    "url = []\n",
    "\n",
    "# Цикл на 33 страницы сайта obrazoval.ru\n",
    "for i in range(1,34):\n",
    "    site = f'https://obrazoval.ru/courses?direction%5B0%5D=%D0%9F%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5&priceFrom=1000&page={i}'\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    req = Request(site,headers=hdr)\n",
    "    page = urlopen(req)\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    link1 = soup.find_all('span',{'class':'ellipsis-3-lines'})\n",
    "    for num in link1:\n",
    "        title.append(num.text) # название курса\n",
    "    link2 = soup.find_all('div', {'class':'q-img q-img--menu'})\n",
    "    for num1 in link2:\n",
    "        try:\n",
    "            if len(title) != len(company): # название компании\n",
    "                company.append(num1['aria-label'])\n",
    "        except:\n",
    "            continue\n",
    "    link3 = soup.find_all('div',{'class':'b-title__custom l-course__price'})\n",
    "    for num2 in link3:\n",
    "        if len(title) != len(price): # Цена курса\n",
    "            price.append(num2.text)\n",
    "    link4 = soup.find_all('span', {'class':'owners__info-rating-count'})\n",
    "    for num3 in link4:\n",
    "        if len(title) != len(raiting_company): # рейтинг компании\n",
    "            raiting_company.append(num3.text)\n",
    "    link5 = soup.find_all('div',{'class':'text-h4 q-mr-xs'})\n",
    "    for num4 in link5:\n",
    "        if len(title) != len(raiting_course): # рейтинг курса\n",
    "            raiting_course.append(num4.text)\n",
    "    link6 = soup.find_all('div',{'class':'l-course__description ellipsis-4-lines text-dark'})\n",
    "    for num5 in link6:\n",
    "        if len(title) != len(descr_course): # краткое описание курса\n",
    "            descr_course.append(num5.text)\n",
    "    link7 = soup.find_all('a',{'class':'q-btn q-btn-item non-selectable no-outline q-btn--unelevated q-btn--rectangle q-btn--actionable q-focusable q-hoverable b-btn b-btn--outline l-course__btn'},href=True)\n",
    "    for num6 in link7:\n",
    "        if len(title) != len(url): # ссылки подробнее\n",
    "            url.append(num6['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataFrame Pandas\n",
    "df = pd.DataFrame({'Название': title, 'Компания': company, \n",
    "'Цена': price, 'РейтингКомп': raiting_company, \n",
    "'РейтингКурса': raiting_course, 'Описание': descr_course, 'Ссылки': url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переходим по найденым ссылкам, достаем информацию из подробнее.\n",
    "skill = []\n",
    "time_course = []\n",
    "course_comments = []\n",
    "try:\n",
    "    for j in range(len(df[\"Ссылки\"])):\n",
    "        site = f'https://obrazoval.ru{df[\"Ссылки\"][j]}'\n",
    "        hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "        req = Request(site,headers=hdr)\n",
    "        page = urlopen(req)\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        lnk_skill = soup.find_all('div', {'class':'l-skills__item'})  # Какие скиллы получаемые за прохождение\n",
    "        buff = []\n",
    "        for key in lnk_skill:\n",
    "            buff.append(re.sub('\\d','', key.text))\n",
    "        skill.append(buff)\n",
    "        buff = []\n",
    "        lnk_time = soup.find_all('div', {'class':'flex items-center'}) # Время обучения\n",
    "        time_course.append(lnk_time[1].text.lstrip()[:-1])\n",
    "        lnk_comment = soup.find_all('a', {'class':'reviews-card__title'}) # Отзывы о курсе(Только тема)\n",
    "        for nak in lnk_comment:\n",
    "            buff.append(nak.text)\n",
    "        course_comments.append(buff)\n",
    "        buff = []\n",
    "except:\n",
    "    print(f'Ошибка - {df[\"Ссылки\"][j]}')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополняем наш DataFrame\n",
    "df['НавыкиПриобр'] = skill\n",
    "df['СрокОбуч'] = time_course\n",
    "df['Коментарии'] = course_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем не нужные колонки\n",
    "df.drop(df.columns[[0, 1]], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем *.csv\n",
    "df.to_csv('Course_IT_byKudryai.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ParsingCity-Znwa00PC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fddff76eb9f1a2a61b37a0ddd46c59f83d28d519a2605606dbbc42a3f6c53a90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
